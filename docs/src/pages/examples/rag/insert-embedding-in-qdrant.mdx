---
title: "Example: Insert Embeddings in Qdrant | RAG | Mastra Docs"
description: Example of using Mastra to store embeddings in Qdrant for similarity search.
---

import { GithubLink } from '../../../components/github-link';

# Insert Embedding in Qdrant

After generating embeddings, you need to store them in a vector database for similarity search. The `QdrantVector` class provides methods to create collections and insert embeddings into Qdrant, a high-performance vector database. This example shows how to store embeddings in Qdrant for later retrieval.

```tsx copy
import { openai } from '@ai-sdk/openai';
import { QdrantVector } from '@mastra/qdrant';
import { MDocument } from '@mastra/rag';
import { embedMany } from 'ai';

const doc = MDocument.fromText('Your text content...');

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map(chunk => chunk.text),
  model: openai.embedding('text-embedding-3-small'),
  maxRetries: 3,
});

const qdrant = new QdrantVector(
  process.env.QDRANT_URL,
  process.env.QDRANT_API_KEY,
);

await qdrant.createIndex({
  indexName: 'test_collection',
  dimension: 1536,
});

await qdrant.upsert({
  indexName: 'test_collection',
  vectors: embeddings,
  metadata: chunks?.map(chunk => ({ text: chunk.text })),
});
```

{/* <br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink link={'https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-qdrant'} /> */}
